{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Albert_cls.ipynb","provenance":[],"collapsed_sections":["MYXbsSniCv-L"],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"333857806cff4d6682b3c3898a744cb0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_4fbc514267aa4361ac22c6ba72731ce4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a33619e14b6b411d81c93a80b4232e54","IPY_MODEL_22c28032542446dfa91ff3f02e7cb111"]}},"4fbc514267aa4361ac22c6ba72731ce4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a33619e14b6b411d81c93a80b4232e54":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_26896cbf07244dddbe16a59d902ca06f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":760289,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":760289,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a86caddc59bb40309ad9cfa2339266c8"}},"22c28032542446dfa91ff3f02e7cb111":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9b716c7ebd644d3e91e60f989511ae69","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 760k/760k [00:53&lt;00:00, 14.3kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9a52211d4e9746c9a2f60ff21d7a9a26"}},"26896cbf07244dddbe16a59d902ca06f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a86caddc59bb40309ad9cfa2339266c8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9b716c7ebd644d3e91e60f989511ae69":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"9a52211d4e9746c9a2f60ff21d7a9a26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"90efd2e1a5864810ae993c9dc2126966":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5c52cde89e8d45da878ded50b58e12f8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_97c3f52190b8454eb3af36e3a15676a6","IPY_MODEL_62c8acb64a16492e80acde4b58f55ad4"]}},"5c52cde89e8d45da878ded50b58e12f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"97c3f52190b8454eb3af36e3a15676a6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_092f7806ce57433a96d8ec4c9a7aecfb","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":1312669,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1312669,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_12504c6f573d4c6b96458f4f1ed7869c"}},"62c8acb64a16492e80acde4b58f55ad4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d451f7bc860a44cfb10d1ce70e53d9a5","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1.31M/1.31M [00:27&lt;00:00, 48.5kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_57aa4a2c5d404fb5bd891f490ba6f16e"}},"092f7806ce57433a96d8ec4c9a7aecfb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"12504c6f573d4c6b96458f4f1ed7869c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d451f7bc860a44cfb10d1ce70e53d9a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"57aa4a2c5d404fb5bd891f490ba6f16e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9fc2ea05d55f48c686c21b0cff558cc2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_65f52be74da5428c8e621b42ecb51dd5","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_35683f1d34644eb5b48f4c1711038cd7","IPY_MODEL_45e90bdde2154f7e95252e0e6561b837"]}},"65f52be74da5428c8e621b42ecb51dd5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"35683f1d34644eb5b48f4c1711038cd7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_610688468abe435797ea0ab11fe002a7","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":685,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":685,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ba4168c743e940588f3949cb06d7d8d8"}},"45e90bdde2154f7e95252e0e6561b837":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_65bf0914132c43c1a85e85b1c566852a","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 685/685 [01:31&lt;00:00, 7.51B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a2defbb16eba45acaaaf269196d9324f"}},"610688468abe435797ea0ab11fe002a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ba4168c743e940588f3949cb06d7d8d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"65bf0914132c43c1a85e85b1c566852a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"a2defbb16eba45acaaaf269196d9324f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ead3603035444310abc1f59b5c91062b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_37098c01d08e4aaf936381bc28e9f4bf","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1358ce51ddb640baa915a3a37c1f9fea","IPY_MODEL_cfc8cade82224743901517f7f4db66d8"]}},"37098c01d08e4aaf936381bc28e9f4bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1358ce51ddb640baa915a3a37c1f9fea":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b6079903093d490697305cc1b6200cb9","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":71509304,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":71509304,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2f5104440bf448d6a88d64c7ac70a931"}},"cfc8cade82224743901517f7f4db66d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d152a83ec1d144caad02de2cdd87d462","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 71.5M/71.5M [01:30&lt;00:00, 788kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d693c7dc11fc48bcb872e2b23d93cecd"}},"b6079903093d490697305cc1b6200cb9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2f5104440bf448d6a88d64c7ac70a931":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d152a83ec1d144caad02de2cdd87d462":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d693c7dc11fc48bcb872e2b23d93cecd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"f7H7eVujTuJ7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623459712903,"user_tz":-330,"elapsed":2422,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"a56167b2-4af9-4775-c0d6-52ddaa5efded"},"source":["import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla V100-SXM2-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dA_bg1RoLYov","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1623459719177,"user_tz":-330,"elapsed":452,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"acbd35c3-398f-4567-e731-d27b233037c7"},"source":["!python --version"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Python 3.7.10\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mJTu45QcnIHy","executionInfo":{"status":"ok","timestamp":1623459731598,"user_tz":-330,"elapsed":9651,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"bca0f41f-8f79-4f02-ec11-9705ef5d6faa"},"source":["!pip install transformers\n","!pip install sentencepiece"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 14.9MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Collecting huggingface-hub==0.0.8\n","  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 49.4MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 48.7MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n","Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n","Collecting sentencepiece\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n","\u001b[K     |████████████████████████████████| 1.2MB 13.4MB/s \n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.95\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"c-BU55B7Ry67"},"source":["# Get data from this link:- (https://drive.google.com/file/d/1bJQ240quwpbkSHlt0h71uebtR5obWrVg/view?usp=sharing)"]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":73},"id":"oorfzDrbnoCL","executionInfo":{"status":"ok","timestamp":1623459893132,"user_tz":-330,"elapsed":19734,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"1d6fe4cd-0666-4dc7-bf86-3a64b4e501a8"},"source":["import pandas as pd\n","from google.colab import files\n","uploaded=files.upload()"],"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-0303b979-2107-4e72-b14b-2e170fc484e1\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-0303b979-2107-4e72-b14b-2e170fc484e1\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving train.csv to train.csv\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dDp1qgmwwFzj"},"source":["# New Section"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"J5X9n3V_DZBI","executionInfo":{"status":"ok","timestamp":1623459906438,"user_tz":-330,"elapsed":432,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"0390bcfb-b886-43ad-d91c-a17e084a6384"},"source":["df= pd.read_csv('train.csv')\n","df.columns=['A','B','C']\n","\n","possible_labels = df.C.unique()\n","\n","label_dict = {}\n","for index, possible_label in enumerate(possible_labels):\n","    label_dict[possible_label] = index\n","\n","df['label'] = df.C.replace(label_dict)\n","df.head()"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>BOS above problem how will it solve ?? EOS</td>\n","      <td>O O O O O O O O O</td>\n","      <td>need_help</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>BOS Hello sir is there anyone EOS</td>\n","      <td>O O O O O O O</td>\n","      <td>Greetings</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>BOS i think canvas login problem was due to br...</td>\n","      <td>O O O O O O O O O O O O O O O O O O</td>\n","      <td>great</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>BOS Please provide me with the link to python ...</td>\n","      <td>O O O O O O O O O O O</td>\n","      <td>community_class_link</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>BOS Understood  EOS</td>\n","      <td>O O O</td>\n","      <td>great</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                   A  ... label\n","0         BOS above problem how will it solve ?? EOS  ...     0\n","1                  BOS Hello sir is there anyone EOS  ...     1\n","2  BOS i think canvas login problem was due to br...  ...     2\n","3  BOS Please provide me with the link to python ...  ...     3\n","4                                BOS Understood  EOS  ...     2\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y_XmFQAcXWgv","executionInfo":{"status":"ok","timestamp":1623459921719,"user_tz":-330,"elapsed":556,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"7fc95355-e95d-450e-86aa-c5bcfbb0a7b5"},"source":["n = len(pd.unique(df['C'])) #number of unique labels\n","print(n)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["151\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":377},"id":"mGLlfy1Fnzxg","executionInfo":{"status":"ok","timestamp":1623459932454,"user_tz":-330,"elapsed":484,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"041235f3-8834-4be3-a655-d2ec14ff9b5f"},"source":["# Load the dataset into a pandas dataframe.\n","      \n","      #df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n","\n","\n","# Report the number of sentences.\n","print('Number of training sentences:')\n","print(df.shape[0])\n","# Display 10 random rows from the data.\n","df.sample(10)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Number of training sentences:\n","3513\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>A</th>\n","      <th>B</th>\n","      <th>C</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>212</th>\n","      <td>BOS Yes sir  EOS</td>\n","      <td>O O O O</td>\n","      <td>Thank_you</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>969</th>\n","      <td>BOS ok sir sure EOS</td>\n","      <td>O O O O O</td>\n","      <td>good_bye</td>\n","      <td>27</td>\n","    </tr>\n","    <tr>\n","      <th>1626</th>\n","      <td>BOS numpy assignment EOS</td>\n","      <td>O O O O</td>\n","      <td>assignment_numpy</td>\n","      <td>88</td>\n","    </tr>\n","    <tr>\n","      <th>153</th>\n","      <td>BOS hello sir, i m implementing the linear reg...</td>\n","      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n","      <td>python_requirements_install</td>\n","      <td>38</td>\n","    </tr>\n","    <tr>\n","      <th>3435</th>\n","      <td>BOS same issue again EOS</td>\n","      <td>O O O O O</td>\n","      <td>need_help</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2954</th>\n","      <td>BOS can i call you sir EOS</td>\n","      <td>O O O O O O O</td>\n","      <td>need_skype_call</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>539</th>\n","      <td>BOS it worked fine\\but this time when am tryin...</td>\n","      <td>O O O O O O O O O O O O O O O O</td>\n","      <td>sorry</td>\n","      <td>37</td>\n","    </tr>\n","    <tr>\n","      <th>1500</th>\n","      <td>BOS yeah just a second EOS</td>\n","      <td>O O O O O O</td>\n","      <td>sure</td>\n","      <td>17</td>\n","    </tr>\n","    <tr>\n","      <th>2476</th>\n","      <td>BOS Its giving result in pycharm but not in br...</td>\n","      <td>O O O O O O O O O O O</td>\n","      <td>need_help</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2825</th>\n","      <td>BOS Please call me again  EOS</td>\n","      <td>O O O O O O</td>\n","      <td>need_skype_call</td>\n","      <td>12</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                      A  ... label\n","212                                    BOS Yes sir  EOS  ...    13\n","969                                 BOS ok sir sure EOS  ...    27\n","1626                           BOS numpy assignment EOS  ...    88\n","153   BOS hello sir, i m implementing the linear reg...  ...    38\n","3435                           BOS same issue again EOS  ...     0\n","2954                         BOS can i call you sir EOS  ...    12\n","539   BOS it worked fine\\but this time when am tryin...  ...    37\n","1500                         BOS yeah just a second EOS  ...    17\n","2476  BOS Its giving result in pycharm but not in br...  ...     0\n","2825                      BOS Please call me again  EOS  ...    12\n","\n","[10 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"ypKFxhx5n_7W","executionInfo":{"status":"ok","timestamp":1623459935928,"user_tz":-330,"elapsed":1,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}}},"source":["sentences = df.A.values\n","labels = df.label.values"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131,"referenced_widgets":["333857806cff4d6682b3c3898a744cb0","4fbc514267aa4361ac22c6ba72731ce4","a33619e14b6b411d81c93a80b4232e54","22c28032542446dfa91ff3f02e7cb111","26896cbf07244dddbe16a59d902ca06f","a86caddc59bb40309ad9cfa2339266c8","9b716c7ebd644d3e91e60f989511ae69","9a52211d4e9746c9a2f60ff21d7a9a26","90efd2e1a5864810ae993c9dc2126966","5c52cde89e8d45da878ded50b58e12f8","97c3f52190b8454eb3af36e3a15676a6","62c8acb64a16492e80acde4b58f55ad4","092f7806ce57433a96d8ec4c9a7aecfb","12504c6f573d4c6b96458f4f1ed7869c","d451f7bc860a44cfb10d1ce70e53d9a5","57aa4a2c5d404fb5bd891f490ba6f16e"]},"id":"f7nO7K_2oJkF","executionInfo":{"status":"ok","timestamp":1623459941500,"user_tz":-330,"elapsed":2946,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"f4c87ce4-1c48-44f0-ef33-2f9b159ce488"},"source":["from transformers import AlbertTokenizer\n","\n","# Load the ALBERT tokenizer.\n","print('Loading ALBERT tokenizer...')\n","tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2', do_lower_case=True)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Loading ALBERT tokenizer...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"333857806cff4d6682b3c3898a744cb0","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=760289.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"90efd2e1a5864810ae993c9dc2126966","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1312669.0, style=ProgressStyle(descript…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AmbFrIjjow3i","executionInfo":{"status":"ok","timestamp":1623459969416,"user_tz":-330,"elapsed":1232,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"8500761e-c0f7-466f-9b65-1bab4bbf0f19"},"source":["max_len = 0\n","\n","# For every sentence...\n","for sent in sentences:\n","\n","    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n","    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n","\n","    # Update the maximum sentence length.\n","    max_len = max(max_len, len(input_ids))\n","\n","print('Max sentence length: ', max_len)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (634 > 512). Running this sequence through the model will result in indexing errors\n"],"name":"stderr"},{"output_type":"stream","text":["Max sentence length:  738\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4vlR3KXep3Wb","executionInfo":{"status":"ok","timestamp":1623459992674,"user_tz":-330,"elapsed":1756,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"7da37449-9b4a-41b3-aa54-335658f7b4be"},"source":["# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in sentences:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 100,           # Pad & truncate all sentences. Just in case there are some longer test sentences, I’ll set the maximum length to 64.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                        truncation=True\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Print sentence 0, now as a list of IDs.\n","print('Original: ', sentences[0])\n","print('Token IDs:', input_ids[0])"],"execution_count":14,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["Original:  BOS above problem how will it solve ?? EOS\n","Token IDs: tensor([    2, 11054,   784,  1448,   184,   129,    32,  8402,    13,    60,\n","           60,    13,  3894,    18,     3,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","            0,     0,     0,     0,     0,     0,     0,     0,     0,     0])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A2Gvo8LJqLc4","executionInfo":{"status":"ok","timestamp":1623460005541,"user_tz":-330,"elapsed":481,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"dd935839-d9a9-4787-9a79-ac3717e0339e"},"source":["from torch.utils.data import TensorDataset, random_split\n","\n","# Combine the training inputs into a TensorDataset.\n","dataset = TensorDataset(input_ids, attention_masks, labels)\n","\n","# Create a 90-10 train-validation split.\n","\n","# Calculate the number of samples to include in each set.\n","train_size = int(0.9 * len(dataset))\n","val_size = len(dataset) - train_size\n","\n","# Divide the dataset by randomly selecting samples.\n","train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n","\n","print('{:>5,} training samples'.format(train_size))\n","print('{:>5,} validation samples'.format(val_size))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["3,161 training samples\n","  352 validation samples\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"D6pTyv3BrF6_","executionInfo":{"status":"ok","timestamp":1623460012938,"user_tz":-330,"elapsed":443,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}}},"source":["from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n","\n","# The DataLoader needs to know our batch size for training, so we specify it \n","# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n","# size of 16 or 32.\n","batch_size = 32\n","\n","# Create the DataLoaders for our training and validation sets.\n","# We'll take training samples in random order. \n","train_dataloader = DataLoader(\n","            train_dataset,  # The training samples.\n","            sampler = RandomSampler(train_dataset), # Select batches randomly\n","            batch_size = batch_size # Trains with this batch size.\n","        )\n","\n","# For validation the order doesn't matter, so we'll just read them sequentially.\n","validation_dataloader = DataLoader(\n","            val_dataset, # The validation samples.\n","            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n","            batch_size = batch_size # Evaluate with this batch size.\n","        )"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":874,"referenced_widgets":["9fc2ea05d55f48c686c21b0cff558cc2","65f52be74da5428c8e621b42ecb51dd5","35683f1d34644eb5b48f4c1711038cd7","45e90bdde2154f7e95252e0e6561b837","610688468abe435797ea0ab11fe002a7","ba4168c743e940588f3949cb06d7d8d8","65bf0914132c43c1a85e85b1c566852a","a2defbb16eba45acaaaf269196d9324f","ead3603035444310abc1f59b5c91062b","37098c01d08e4aaf936381bc28e9f4bf","1358ce51ddb640baa915a3a37c1f9fea","cfc8cade82224743901517f7f4db66d8","b6079903093d490697305cc1b6200cb9","2f5104440bf448d6a88d64c7ac70a931","d152a83ec1d144caad02de2cdd87d462","d693c7dc11fc48bcb872e2b23d93cecd"]},"id":"z8bh64fKrTGC","executionInfo":{"status":"ok","timestamp":1623460093569,"user_tz":-330,"elapsed":10871,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"4b60cdb8-3752-4779-8d33-fd7630d159bd"},"source":["from transformers import     AlbertForSequenceClassification, AdamW, AlbertConfig\n","\n","# Load AlertForSequenceClassification, the pretrained ALBERT model with a single \n","# linear classification layer on top. \n","model = AlbertForSequenceClassification.from_pretrained(\n","    \"albert-large-v2\", # Use the 12-layer BERT model, with an uncased vocab.\n","    num_labels =151 , # The number of output labels--2 for binary classification.\n","                    # You can increase this for multi-class tasks.   \n","    output_attentions = False, # Whether the model returns attentions weights.\n","    output_hidden_states = False, # Whether the model returns all hidden-states.\n","    return_dict=False\n",")\n","\n","# Tell pytorch to run this model on the GPU.\n","model.cuda()"],"execution_count":17,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9fc2ea05d55f48c686c21b0cff558cc2","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=685.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ead3603035444310abc1f59b5c91062b","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=71509304.0, style=ProgressStyle(descrip…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.decoder.weight', 'predictions.dense.bias', 'predictions.bias', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.decoder.bias', 'predictions.LayerNorm.weight']\n","- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["AlbertForSequenceClassification(\n","  (albert): AlbertModel(\n","    (embeddings): AlbertEmbeddings(\n","      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n","      (position_embeddings): Embedding(512, 128)\n","      (token_type_embeddings): Embedding(2, 128)\n","      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0, inplace=False)\n","    )\n","    (encoder): AlbertTransformer(\n","      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=1024, bias=True)\n","      (albert_layer_groups): ModuleList(\n","        (0): AlbertLayerGroup(\n","          (albert_layers): ModuleList(\n","            (0): AlbertLayer(\n","              (full_layer_layer_norm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (attention): AlbertAttention(\n","                (query): Linear(in_features=1024, out_features=1024, bias=True)\n","                (key): Linear(in_features=1024, out_features=1024, bias=True)\n","                (value): Linear(in_features=1024, out_features=1024, bias=True)\n","                (attention_dropout): Dropout(p=0, inplace=False)\n","                (output_dropout): Dropout(p=0, inplace=False)\n","                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              )\n","              (ffn): Linear(in_features=1024, out_features=4096, bias=True)\n","              (ffn_output): Linear(in_features=4096, out_features=1024, bias=True)\n","              (dropout): Dropout(p=0, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (pooler): Linear(in_features=1024, out_features=1024, bias=True)\n","    (pooler_activation): Tanh()\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=1024, out_features=151, bias=True)\n",")"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mqViv3HLttj8","executionInfo":{"status":"ok","timestamp":1623460116397,"user_tz":-330,"elapsed":454,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"bb57e4fa-7a73-4ccd-fc17-e1478d5db5ff"},"source":["# Get all of the model's parameters as a list of tuples.\n","params = list(model.named_parameters())\n","\n","print('The ALBERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["The ALBERT model has 27 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","albert.embeddings.word_embeddings.weight                (30000, 128)\n","albert.embeddings.position_embeddings.weight              (512, 128)\n","albert.embeddings.token_type_embeddings.weight              (2, 128)\n","albert.embeddings.LayerNorm.weight                            (128,)\n","albert.embeddings.LayerNorm.bias                              (128,)\n","\n","==== First Transformer ====\n","\n","albert.encoder.embedding_hidden_mapping_in.weight        (1024, 128)\n","albert.encoder.embedding_hidden_mapping_in.bias              (1024,)\n","albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.weight      (1024,)\n","albert.encoder.albert_layer_groups.0.albert_layers.0.full_layer_layer_norm.bias      (1024,)\n","albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.weight (1024, 1024)\n","albert.encoder.albert_layer_groups.0.albert_layers.0.attention.query.bias      (1024,)\n","albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.weight (1024, 1024)\n","albert.encoder.albert_layer_groups.0.albert_layers.0.attention.key.bias      (1024,)\n","albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.weight (1024, 1024)\n","albert.encoder.albert_layer_groups.0.albert_layers.0.attention.value.bias      (1024,)\n","albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.weight (1024, 1024)\n","albert.encoder.albert_layer_groups.0.albert_layers.0.attention.dense.bias      (1024,)\n","albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.weight      (1024,)\n","albert.encoder.albert_layer_groups.0.albert_layers.0.attention.LayerNorm.bias      (1024,)\n","albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.weight (4096, 1024)\n","albert.encoder.albert_layer_groups.0.albert_layers.0.ffn.bias      (4096,)\n","\n","==== Output Layer ====\n","\n","albert.pooler.weight                                    (1024, 1024)\n","albert.pooler.bias                                           (1024,)\n","classifier.weight                                        (151, 1024)\n","classifier.bias                                               (151,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jaVUxp-_t9CK","executionInfo":{"status":"ok","timestamp":1623460136010,"user_tz":-330,"elapsed":436,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}}},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","# I believe the 'W' stands for 'Weight Decay fix\"\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )\n"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"HWTI2DX0uHd7","executionInfo":{"status":"ok","timestamp":1623460150394,"user_tz":-330,"elapsed":441,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}}},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 4\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"atkYGry5uP2X","executionInfo":{"status":"ok","timestamp":1623460152142,"user_tz":-330,"elapsed":1,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}}},"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"GxiL9SFUutXL","executionInfo":{"status":"ok","timestamp":1623460155547,"user_tz":-330,"elapsed":482,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}}},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"99Jh7fdN8IUr","executionInfo":{"status":"ok","timestamp":1623460157399,"user_tz":-330,"elapsed":2,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}}},"source":["torch.cuda.empty_cache()"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zq3Wgu-YuzlM","executionInfo":{"status":"ok","timestamp":1623460386282,"user_tz":-330,"elapsed":227031,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"e50d2ff0-0f8f-4ef5-bd90-a667a2630c8a"},"source":["import random\n","import numpy as np\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        # It returns different numbers of parameters depending on what arguments\n","        # arge given and what flags are set. For our useage here, it returns\n","        # the loss (because we provided labels) and the \"logits\"--the model\n","        # outputs prior to activation.\n","        loss, logits = model(b_input_ids, \n","                             token_type_ids=None, \n","                             attention_mask=b_input_mask, \n","                             labels=b_labels)\n","\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            # Get the \"logits\" output by the model. The \"logits\" are the output\n","            # values prior to applying an activation function like the softmax.\n","            (loss, logits) = model(b_input_ids, \n","                                   token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","            \n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n"],"execution_count":25,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n","  Batch    40  of     99.    Elapsed: 0:00:22.\n","  Batch    80  of     99.    Elapsed: 0:00:44.\n","\n","  Average training loss: 3.14\n","  Training epcoh took: 0:00:55\n","\n","Running Validation...\n","  Accuracy: 0.53\n","  Validation Loss: 2.44\n","  Validation took: 0:00:02\n","\n","======== Epoch 2 / 4 ========\n","Training...\n","  Batch    40  of     99.    Elapsed: 0:00:22.\n","  Batch    80  of     99.    Elapsed: 0:00:44.\n","\n","  Average training loss: 2.23\n","  Training epcoh took: 0:00:54\n","\n","Running Validation...\n","  Accuracy: 0.56\n","  Validation Loss: 2.13\n","  Validation took: 0:00:02\n","\n","======== Epoch 3 / 4 ========\n","Training...\n","  Batch    40  of     99.    Elapsed: 0:00:22.\n","  Batch    80  of     99.    Elapsed: 0:00:44.\n","\n","  Average training loss: 1.99\n","  Training epcoh took: 0:00:54\n","\n","Running Validation...\n","  Accuracy: 0.57\n","  Validation Loss: 2.00\n","  Validation took: 0:00:02\n","\n","======== Epoch 4 / 4 ========\n","Training...\n","  Batch    40  of     99.    Elapsed: 0:00:22.\n","  Batch    80  of     99.    Elapsed: 0:00:44.\n","\n","  Average training loss: 1.83\n","  Training epcoh took: 0:00:54\n","\n","Running Validation...\n","  Accuracy: 0.57\n","  Validation Loss: 1.97\n","  Validation took: 0:00:02\n","\n","Training complete!\n","Total training took 0:03:47 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LRcDSpyRv22I","colab":{"base_uri":"https://localhost:8080/","height":203},"executionInfo":{"status":"ok","timestamp":1623150407689,"user_tz":-330,"elapsed":684,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"12953e98-f96a-4177-dcc2-f288d77c366d"},"source":["import pandas as pd\n","\n","# Display floats with two decimal places.\n","pd.set_option('precision', 2)\n","\n","# Create a DataFrame from our training statistics.\n","df_stats = pd.DataFrame(data=training_stats)\n","\n","# Use the 'epoch' as the row index.\n","df_stats = df_stats.set_index('epoch')\n","\n","# A hack to force the column headers to wrap.\n","#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n","\n","# Display the table.\n","df_stats"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Training Loss</th>\n","      <th>Valid. Loss</th>\n","      <th>Valid. Accur.</th>\n","      <th>Training Time</th>\n","      <th>Validation Time</th>\n","    </tr>\n","    <tr>\n","      <th>epoch</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>3.17</td>\n","      <td>2.27</td>\n","      <td>0.53</td>\n","      <td>0:00:55</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2.26</td>\n","      <td>2.00</td>\n","      <td>0.59</td>\n","      <td>0:00:54</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>2.02</td>\n","      <td>1.96</td>\n","      <td>0.58</td>\n","      <td>0:00:55</td>\n","      <td>0:00:02</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.86</td>\n","      <td>1.91</td>\n","      <td>0.58</td>\n","      <td>0:00:55</td>\n","      <td>0:00:02</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n","epoch                                                                         \n","1               3.17         2.27           0.53       0:00:55         0:00:02\n","2               2.26         2.00           0.59       0:00:54         0:00:02\n","3               2.02         1.96           0.58       0:00:55         0:00:02\n","4               1.86         1.91           0.58       0:00:55         0:00:02"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"VVs_gKUAB5gc"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MYXbsSniCv-L"},"source":["## Test"]},{"cell_type":"markdown","metadata":{"id":"ShTIvrn3T8Xg"},"source":["# Get data from this link:- (https://drive.google.com/file/d/1-Tg3Znr6c1_bwyHaUihUlT2JBH6QkeNG/view?usp=sharing)"]},{"cell_type":"code","metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":73},"id":"rjLC4u2GT9BV","executionInfo":{"status":"ok","timestamp":1623150606646,"user_tz":-330,"elapsed":26921,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"1fe8600d-7929-4308-cacf-6919af40ffae"},"source":["import pandas as pd\n","from google.colab import files\n","uploaded=files.upload()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-4f09f26c-705c-41b2-8539-035d3d43b668\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-4f09f26c-705c-41b2-8539-035d3d43b668\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving test.csv to test.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":195},"id":"TJZTVXMcUwvG","executionInfo":{"status":"ok","timestamp":1619342336160,"user_tz":-330,"elapsed":1153,"user":{"displayName":"Ritesh Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKd4Dr5t3Pive3Ol3-3TSI0JCTSEC0cot01Ami=s64","userId":"18051714937796063882"}},"outputId":"8c637fd0-f41f-42b9-b4c9-4897cf31f7b7"},"source":["# df = pd.read_csv('test2.csv')\n","\n","# possible_labels = df.label.unique()\n","\n","# label_dict = {}\n","# for index, possible_label in enumerate(possible_labels):\n","#     label_dict[possible_label] = index\n","\n","# df['labeled'] = df.label.replace(label_dict)\n","# df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>Unnamed: 1</th>\n","      <th>label</th>\n","      <th>labeled</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>BOS Actually virat told that kernel trick is u...</td>\n","      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n","      <td>svm_doubt</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>BOS It&amp;apos;s not showing the error as FALSE EOS</td>\n","      <td>O O O O O O O O O</td>\n","      <td>O</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>BOS Okay np EOS</td>\n","      <td>O O O O</td>\n","      <td>good_bye</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>BOS Good Evening Sir/Madam I have a doubt in m...</td>\n","      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n","      <td>assignment_python</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>BOS can u just send me that initial drive code...</td>\n","      <td>O O O O O O O O O O O O O O O O O O O O O O O O</td>\n","      <td>drive_code_colab</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                            sentence  ... labeled\n","0  BOS Actually virat told that kernel trick is u...  ...       0\n","1   BOS It&apos;s not showing the error as FALSE EOS  ...       1\n","2                                    BOS Okay np EOS  ...       2\n","3  BOS Good Evening Sir/Madam I have a doubt in m...  ...       3\n","4  BOS can u just send me that initial drive code...  ...       4\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3b5oLIY_ZnX","executionInfo":{"status":"ok","timestamp":1623151135375,"user_tz":-330,"elapsed":750,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"9eb94ca1-2c11-4324-92c6-459c71dd4128"},"source":["import pandas as pd\n","\n","#Load the dataset into a pandas dataframe.\n","df = pd.read_csv('test.csv', header=None)\n","df.columns = ['sentence', 'Unnamed: 1', 'label']\n","\n","possible_labels = df.label.unique()\n","\n","label_dict = {}\n","for index, possible_label in enumerate(possible_labels):\n","    label_dict[possible_label] = index\n","\n","df['labeled'] = df.label.replace(label_dict)\n","df.head()\n","\n","# Report the number of sentences.\n","print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of test sentences: 434\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cOJuISvvWSa6","executionInfo":{"status":"ok","timestamp":1623151164673,"user_tz":-330,"elapsed":695,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"9c76c212-e8f5-4fcc-d92e-910510205af0"},"source":["# Create sentence and label lists\n","sentences = df.sentence.values\n","labels = df.labeled.values\n","\n","# Tokenize all of the sentences and map the tokens to thier word IDs.\n","input_ids = []\n","attention_masks = []\n","\n","# For every sentence...\n","for sent in sentences:\n","    # `encode_plus` will:\n","    #   (1) Tokenize the sentence.\n","    #   (2) Prepend the `[CLS]` token to the start.\n","    #   (3) Append the `[SEP]` token to the end.\n","    #   (4) Map tokens to their IDs.\n","    #   (5) Pad or truncate the sentence to `max_length`\n","    #   (6) Create attention masks for [PAD] tokens.\n","    encoded_dict = tokenizer.encode_plus(\n","                        sent,                      # Sentence to encode.\n","                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                        max_length = 64,           # Pad & truncate all sentences.\n","                        pad_to_max_length = True,\n","                        return_attention_mask = True,   # Construct attn. masks.\n","                        return_tensors = 'pt',     # Return pytorch tensors.\n","                   )\n","    \n","    # Add the encoded sentence to the list.    \n","    input_ids.append(encoded_dict['input_ids'])\n","    \n","    # And its attention mask (simply differentiates padding from non-padding).\n","    attention_masks.append(encoded_dict['attention_mask'])\n","\n","# Convert the lists into tensors.\n","input_ids = torch.cat(input_ids, dim=0)\n","attention_masks = torch.cat(attention_masks, dim=0)\n","labels = torch.tensor(labels)\n","\n","# Set the batch size.  \n","batch_size = 32  \n","\n","# Create the DataLoader.\n","prediction_data = TensorDataset(input_ids, attention_masks, labels)\n","prediction_sampler = SequentialSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2110: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":417},"id":"iNn6AXAjUZuy","executionInfo":{"status":"ok","timestamp":1623151170524,"user_tz":-330,"elapsed":785,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"9466d6e4-e90a-42a7-a96f-eabb76646ba4"},"source":["df = pd.read_csv('test.csv', header=None)\n","df.columns = ['sentence', 'Unnamed: 1', 'label']\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>Unnamed: 1</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>BOS Actually virat told that kernel trick is u...</td>\n","      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n","      <td>svm_doubt</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>BOS It&amp;apos;s not showing the error as FALSE EOS</td>\n","      <td>O O O O O O O O O</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>BOS Okay np EOS</td>\n","      <td>O O O O</td>\n","      <td>good_bye</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>BOS Good Evening Sir/Madam I have a doubt in m...</td>\n","      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n","      <td>assignment_python</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>BOS can u just send me that initial drive code...</td>\n","      <td>O O O O O O O O O O O O O O O O O O O O O O O O</td>\n","      <td>drive_code_colab</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>429</th>\n","      <td>BOS x=tf.Variable(5)xinit=tf.global_variables_...</td>\n","      <td>O O O O O O O O O O O O O O O</td>\n","      <td>need_help</td>\n","    </tr>\n","    <tr>\n","      <th>430</th>\n","      <td>BOS &lt;partlist type=started alt= OId=ad43697d-0...</td>\n","      <td>O O O O O O O O O O</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>431</th>\n","      <td>BOS Thanks you sir EOS</td>\n","      <td>O O O O O</td>\n","      <td>Thank_you</td>\n","    </tr>\n","    <tr>\n","      <th>432</th>\n","      <td>BOS &lt;URIObject uri=https://api.asm.skype.com/v...</td>\n","      <td>O O O O O O O O O O O O O O O O O O O O O</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>433</th>\n","      <td>BOS Sir I m from 22nd Feb ml batch.. I have a ...</td>\n","      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n","      <td>mongodb_installation</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>434 rows × 3 columns</p>\n","</div>"],"text/plain":["                                              sentence  ...                 label\n","0    BOS Actually virat told that kernel trick is u...  ...             svm_doubt\n","1     BOS It&apos;s not showing the error as FALSE EOS  ...                     O\n","2                                      BOS Okay np EOS  ...              good_bye\n","3    BOS Good Evening Sir/Madam I have a doubt in m...  ...     assignment_python\n","4    BOS can u just send me that initial drive code...  ...      drive_code_colab\n","..                                                 ...  ...                   ...\n","429  BOS x=tf.Variable(5)xinit=tf.global_variables_...  ...             need_help\n","430  BOS <partlist type=started alt= OId=ad43697d-0...  ...                     O\n","431                             BOS Thanks you sir EOS  ...             Thank_you\n","432  BOS <URIObject uri=https://api.asm.skype.com/v...  ...                     O\n","433  BOS Sir I m from 22nd Feb ml batch.. I have a ...  ...  mongodb_installation\n","\n","[434 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":402},"id":"Gx6Tb3oRMNrQ","executionInfo":{"status":"ok","timestamp":1619342291938,"user_tz":-330,"elapsed":1394,"user":{"displayName":"Ritesh Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKd4Dr5t3Pive3Ol3-3TSI0JCTSEC0cot01Ami=s64","userId":"18051714937796063882"}},"outputId":"8d2e8f17-872f-4839-9083-93eb10104fcd"},"source":["# df = pd.read_csv('test2.csv')\n","# df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence</th>\n","      <th>Unnamed: 1</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>BOS Actually virat told that kernel trick is u...</td>\n","      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n","      <td>svm_doubt</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>BOS It&amp;apos;s not showing the error as FALSE EOS</td>\n","      <td>O O O O O O O O O</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>BOS Okay np EOS</td>\n","      <td>O O O O</td>\n","      <td>good_bye</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>BOS Good Evening Sir/Madam I have a doubt in m...</td>\n","      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n","      <td>assignment_python</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>BOS can u just send me that initial drive code...</td>\n","      <td>O O O O O O O O O O O O O O O O O O O O O O O O</td>\n","      <td>drive_code_colab</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>429</th>\n","      <td>BOS x=tf.Variable(5)xinit=tf.global_variables_...</td>\n","      <td>O O O O O O O O O O O O O O O</td>\n","      <td>need_help</td>\n","    </tr>\n","    <tr>\n","      <th>430</th>\n","      <td>BOS &lt;partlist type=started alt= OId=ad43697d-0...</td>\n","      <td>O O O O O O O O O O</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>431</th>\n","      <td>BOS Thanks you sir EOS</td>\n","      <td>O O O O O</td>\n","      <td>Thank_you</td>\n","    </tr>\n","    <tr>\n","      <th>432</th>\n","      <td>BOS &lt;URIObject uri=https://api.asm.skype.com/v...</td>\n","      <td>O O O O O O O O O O O O O O O O O O O O O</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>433</th>\n","      <td>BOS Sir I m from 22nd Feb ml batch.. I have a ...</td>\n","      <td>O O O O O O O O O O O O O O O O O O O O O O O ...</td>\n","      <td>mongodb_installation</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>434 rows × 3 columns</p>\n","</div>"],"text/plain":["                                              sentence  ...                 label\n","0    BOS Actually virat told that kernel trick is u...  ...             svm_doubt\n","1     BOS It&apos;s not showing the error as FALSE EOS  ...                     O\n","2                                      BOS Okay np EOS  ...              good_bye\n","3    BOS Good Evening Sir/Madam I have a doubt in m...  ...     assignment_python\n","4    BOS can u just send me that initial drive code...  ...      drive_code_colab\n","..                                                 ...  ...                   ...\n","429  BOS x=tf.Variable(5)xinit=tf.global_variables_...  ...             need_help\n","430  BOS <partlist type=started alt= OId=ad43697d-0...  ...                     O\n","431                             BOS Thanks you sir EOS  ...             Thank_you\n","432  BOS <URIObject uri=https://api.asm.skype.com/v...  ...                     O\n","433  BOS Sir I m from 22nd Feb ml batch.. I have a ...  ...  mongodb_installation\n","\n","[434 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_74ef8Cc_nAU","executionInfo":{"status":"ok","timestamp":1623151182860,"user_tz":-330,"elapsed":2410,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"405762a0-3bbb-418e-9d71-3da1dcc3788e"},"source":["# Prediction on test set\n","\n","print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n","\n","# Put model in evaluation mode\n","model.eval()\n","\n","# Tracking variables \n","predictions , true_labels = [], []\n","\n","# Predict \n","for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask, b_labels = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids, token_type_ids=None, \n","                      attention_mask=b_input_mask)\n","\n","  logits = outputs[0]\n","\n","  # Move logits and labels to CPU\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  \n","  # Store predictions and true labels\n","  predictions.append(logits)\n","  true_labels.append(label_ids)\n","\n","print('    DONE.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Predicting labels for 434 test sentences...\n","    DONE.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"huf6c0PJ_wOp","executionInfo":{"status":"ok","timestamp":1623151189798,"user_tz":-330,"elapsed":568,"user":{"displayName":"colab0 ineuron","photoUrl":"","userId":"16851312232179065356"}},"outputId":"4ca16ffe-671d-481b-f9a8-ded606f7b7b7"},"source":["import os\n","\n","# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n","\n","output_dir = './model_save/'\n","\n","# Create output directory if needed\n","if not os.path.exists(output_dir):\n","    os.makedirs(output_dir)\n","\n","print(\"Saving model to %s\" % output_dir)\n","\n","# Save a trained model, configuration and tokenizer using `save_pretrained()`.\n","# They can then be reloaded using `from_pretrained()`\n","model_to_save = model.module if hasattr(model, 'module') else model  # Take care of distributed/parallel training\n","model_to_save.save_pretrained(output_dir)\n","tokenizer.save_pretrained(output_dir)\n","\n","# Good practice: save your training arguments together with the trained model\n","# torch.save(args, os.path.join(output_dir, 'training_args.bin'))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Saving model to ./model_save/\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["('./model_save/tokenizer_config.json',\n"," './model_save/special_tokens_map.json',\n"," './model_save/spiece.model',\n"," './model_save/added_tokens.json')"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V9nh272PVQxH","executionInfo":{"status":"ok","timestamp":1619342497514,"user_tz":-330,"elapsed":31920,"user":{"displayName":"Ritesh Yadav","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhKd4Dr5t3Pive3Ol3-3TSI0JCTSEC0cot01Ami=s64","userId":"18051714937796063882"}},"outputId":"e92a8227-13ee-4815-a8ef-612b272f3ec7"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cTZfOjfFYZfG"},"source":[""],"execution_count":null,"outputs":[]}]}